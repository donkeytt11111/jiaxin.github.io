<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>刘佳鑫笔记</title><link>https://donkeytt11111.github.io/jiaxin.github.io</link><description>欢迎您</description><copyright>刘佳鑫笔记</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://github.githubassets.com/favicons/favicon.svg</url><title>avatar</title><link>https://donkeytt11111.github.io/jiaxin.github.io</link></image><lastBuildDate>Wed, 12 Jun 2024 02:46:31 +0000</lastBuildDate><managingEditor>刘佳鑫笔记</managingEditor><ttl>60</ttl><webMaster>刘佳鑫笔记</webMaster><item><title>harbor_docker_compose.yaml</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/harbor_docker_compose.yaml.html</link><description>```yaml&#13;
version: '2.3'&#13;
services:&#13;
  log:&#13;
    image: goharbor/harbor-log:v2.11.0&#13;
    container_name: harbor-log&#13;
    restart: always&#13;
    cap_drop:&#13;
      - ALL&#13;
    cap_add:&#13;
      - CHOWN&#13;
      - DAC_OVERRIDE&#13;
      - SETGID&#13;
      - SETUID&#13;
    volumes:&#13;
      - /var/log/harbor/:/var/log/docker/:z&#13;
      - type: bind&#13;
        source: ./common/config/log/logrotate.conf&#13;
        target: /etc/logrotate.d/logrotate.conf&#13;
      - type: bind&#13;
        source: ./common/config/log/rsyslog_docker.conf&#13;
        target: /etc/rsyslog.d/rsyslog_docker.conf&#13;
    ports:&#13;
      - 127.0.0.1:1514:10514&#13;
    networks:&#13;
      - harbor&#13;
  registry:&#13;
    image: goharbor/registry-photon:v2.11.0&#13;
    container_name: registry&#13;
    restart: always&#13;
    cap_drop:&#13;
      - ALL&#13;
    cap_add:&#13;
      - CHOWN&#13;
      - SETGID&#13;
      - SETUID&#13;
    volumes:&#13;
      - /data/registry:/storage:z&#13;
      - ./common/config/registry/:/etc/registry/:z&#13;
      - type: bind&#13;
        source: /data/secret/registry/root.crt&#13;
        target: /etc/registry/root.crt&#13;
      - type: bind&#13;
        source: ./common/config/shared/trust-certificates&#13;
        target: /harbor_cust_cert&#13;
    networks:&#13;
      - harbor&#13;
    depends_on:&#13;
      - log&#13;
    logging:&#13;
      driver: 'syslog'&#13;
      options:&#13;
        syslog-address: 'tcp://localhost:1514'&#13;
        tag: 'registry'&#13;
  registryctl:&#13;
    image: goharbor/harbor-registryctl:v2.11.0&#13;
    container_name: registryctl&#13;
    env_file:&#13;
      - ./common/config/registryctl/env&#13;
    restart: always&#13;
    cap_drop:&#13;
      - ALL&#13;
    cap_add:&#13;
      - CHOWN&#13;
      - SETGID&#13;
      - SETUID&#13;
    volumes:&#13;
      - /data/registry:/storage:z&#13;
      - ./common/config/registry/:/etc/registry/:z&#13;
      - type: bind&#13;
        source: ./common/config/registryctl/config.yml&#13;
        target: /etc/registryctl/config.yml&#13;
      - type: bind&#13;
        source: ./common/config/shared/trust-certificates&#13;
        target: /harbor_cust_cert&#13;
    networks:&#13;
      - harbor&#13;
    depends_on:&#13;
      - log&#13;
    logging:&#13;
      driver: 'syslog'&#13;
      options:&#13;
        syslog-address: 'tcp://localhost:1514'&#13;
        tag: 'registryctl'&#13;
  postgresql:&#13;
    image: goharbor/harbor-db:v2.11.0&#13;
    container_name: harbor-db&#13;
    restart: always&#13;
    cap_drop:&#13;
      - ALL&#13;
    cap_add:&#13;
      - CHOWN&#13;
      - DAC_OVERRIDE&#13;
      - SETGID&#13;
      - SETUID&#13;
    volumes:&#13;
      - /data/database:/var/lib/postgresql/data:z&#13;
    networks:&#13;
      harbor:&#13;
    env_file:&#13;
      - ./common/config/db/env&#13;
    depends_on:&#13;
      - log&#13;
    logging:&#13;
      driver: 'syslog'&#13;
      options:&#13;
        syslog-address: 'tcp://localhost:1514'&#13;
        tag: 'postgresql'&#13;
    shm_size: '1gb'&#13;
  core:&#13;
    image: goharbor/harbor-core:v2.11.0&#13;
    container_name: harbor-core&#13;
    env_file:&#13;
      - ./common/config/core/env&#13;
    restart: always&#13;
    cap_drop:&#13;
      - ALL&#13;
    cap_add:&#13;
      - SETGID&#13;
      - SETUID&#13;
    volumes:&#13;
      - /data/ca_download/:/etc/core/ca/:z&#13;
      - /data/:/data/:z&#13;
      - ./common/config/core/certificates/:/etc/core/certificates/:z&#13;
      - type: bind&#13;
        source: ./common/config/core/app.conf&#13;
        target: /etc/core/app.conf&#13;
      - type: bind&#13;
        source: /data/secret/core/private_key.pem&#13;
        target: /etc/core/private_key.pem&#13;
      - type: bind&#13;
        source: /data/secret/keys/secretkey&#13;
        target: /etc/core/key&#13;
      - type: bind&#13;
        source: ./common/config/shared/trust-certificates&#13;
        target: /harbor_cust_cert&#13;
    networks:&#13;
      harbor:&#13;
    depends_on:&#13;
      - log&#13;
      - registry&#13;
      - redis&#13;
      - postgresql&#13;
    logging:&#13;
      driver: 'syslog'&#13;
      options:&#13;
        syslog-address: 'tcp://localhost:1514'&#13;
        tag: 'core'&#13;
  portal:&#13;
    image: goharbor/harbor-portal:v2.11.0&#13;
    container_name: harbor-portal&#13;
    restart: always&#13;
    cap_drop:&#13;
      - ALL&#13;
    cap_add:&#13;
      - CHOWN&#13;
      - SETGID&#13;
      - SETUID&#13;
      - NET_BIND_SERVICE&#13;
    volumes:&#13;
      - type: bind&#13;
        source: ./common/config/portal/nginx.conf&#13;
        target: /etc/nginx/nginx.conf&#13;
    networks:&#13;
      - harbor&#13;
    depends_on:&#13;
      - log&#13;
    logging:&#13;
      driver: 'syslog'&#13;
      options:&#13;
        syslog-address: 'tcp://localhost:1514'&#13;
        tag: 'portal'&#13;
&#13;
  jobservice:&#13;
    image: goharbor/harbor-jobservice:v2.11.0&#13;
    container_name: harbor-jobservice&#13;
    env_file:&#13;
      - ./common/config/jobservice/env&#13;
    restart: always&#13;
    cap_drop:&#13;
      - ALL&#13;
    cap_add:&#13;
      - CHOWN&#13;
      - SETGID&#13;
      - SETUID&#13;
    volumes:&#13;
      - /data/job_logs:/var/log/jobs:z&#13;
      - type: bind&#13;
        source: ./common/config/jobservice/config.yml&#13;
        target: /etc/jobservice/config.yml&#13;
      - type: bind&#13;
        source: ./common/config/shared/trust-certificates&#13;
        target: /harbor_cust_cert&#13;
    networks:&#13;
      - harbor&#13;
    depends_on:&#13;
      - core&#13;
    logging:&#13;
      driver: 'syslog'&#13;
      options:&#13;
        syslog-address: 'tcp://localhost:1514'&#13;
        tag: 'jobservice'&#13;
  redis:&#13;
    image: goharbor/redis-photon:v2.11.0&#13;
    container_name: redis&#13;
    restart: always&#13;
    cap_drop:&#13;
      - ALL&#13;
    cap_add:&#13;
      - CHOWN&#13;
      - SETGID&#13;
      - SETUID&#13;
    volumes:&#13;
      - /data/redis:/var/lib/redis&#13;
    networks:&#13;
      harbor:&#13;
    depends_on:&#13;
      - log&#13;
    logging:&#13;
      driver: 'syslog'&#13;
      options:&#13;
        syslog-address: 'tcp://localhost:1514'&#13;
        tag: 'redis'&#13;
  proxy:&#13;
    image: goharbor/nginx-photon:v2.11.0&#13;
    container_name: nginx&#13;
    restart: always&#13;
    cap_drop:&#13;
      - ALL&#13;
    cap_add:&#13;
      - CHOWN&#13;
      - SETGID&#13;
      - SETUID&#13;
      - NET_BIND_SERVICE&#13;
    volumes:&#13;
      - ./common/config/nginx:/etc/nginx:z&#13;
      - /data/secret/cert:/etc/cert:z&#13;
      - type: bind&#13;
        source: ./common/config/shared/trust-certificates&#13;
        target: /harbor_cust_cert&#13;
    networks:&#13;
      - harbor&#13;
    ports:&#13;
      - 8888:8080&#13;
      - 443:8443&#13;
    depends_on:&#13;
      - registry&#13;
      - core&#13;
      - portal&#13;
      - log&#13;
    logging:&#13;
      driver: 'syslog'&#13;
      options:&#13;
        syslog-address: 'tcp://localhost:1514'&#13;
        tag: 'proxy'&#13;
networks:&#13;
  harbor:&#13;
    external: false。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/harbor_docker_compose.yaml.html</guid><pubDate>Wed, 12 Jun 2024 02:45:26 +0000</pubDate></item><item><title>harbor.yaml</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/harbor.yaml.html</link><description>```yaml&#13;
# Configuration file of Harbor&#13;
&#13;
# The IP address or hostname to access admin UI and registry service.&#13;
# DO NOT use localhost or 127.0.0.1, because Harbor needs to be accessed by external clients.&#13;
hostname: 172.16.8.3&#13;
# http related config&#13;
http:&#13;
  # port for http, default is 80. If https enabled, this port will redirect to https port&#13;
  port: 80&#13;
&#13;
# https related config&#13;
https:&#13;
  # https port for harbor, default is 443&#13;
  port: 443&#13;
  # The path of cert and key files for nginx&#13;
  certificate: /home/test/harbor/harbor/172.16.8.3.crt&#13;
  private_key: /home/test/harbor/harbor/172.16.8.3.key&#13;
  # enable strong ssl ciphers (default: false)&#13;
  # strong_ssl_ciphers: false&#13;
&#13;
# # Harbor will set ipv4 enabled only by default if this block is not configured&#13;
# # Otherwise, please uncomment this block to configure your own ip_family stacks&#13;
# ip_family:&#13;
#   # ipv6Enabled set to true if ipv6 is enabled in docker network, currently it affected the nginx related component&#13;
#   ipv6:&#13;
#     enabled: false&#13;
#   # ipv4Enabled set to true by default, currently it affected the nginx related component&#13;
#   ipv4:&#13;
#     enabled: true&#13;
&#13;
# # Uncomment following will enable tls communication between all harbor components&#13;
# internal_tls:&#13;
#   # set enabled to true means internal tls is enabled&#13;
#   enabled: true&#13;
#   # put your cert and key files on dir&#13;
#   dir: /etc/harbor/tls/internal&#13;
&#13;
&#13;
# Uncomment external_url if you want to enable external proxy&#13;
# And when it enabled the hostname will no longer used&#13;
# external_url: https://reg.mydomain.com:8433&#13;
&#13;
# The initial password of Harbor admin&#13;
# It only works in first time to install harbor&#13;
# Remember Change the admin password from UI after launching Harbor.&#13;
harbor_admin_password: Harbor12345&#13;
&#13;
# Harbor DB configuration&#13;
database:&#13;
  # The password for the root user of Harbor DB. Change this before any production use.&#13;
  password: root123&#13;
  # The maximum number of connections in the idle connection pool. If it &lt;=0, no idle connections are retained.&#13;
  max_idle_conns: 100&#13;
  # The maximum number of open connections to the database. If it &lt;= 0, then there is no limit on the number of open connections.&#13;
  # Note: the default number of connections is 1024 for postgres of harbor.&#13;
  max_open_conns: 900&#13;
  # The maximum amount of time a connection may be reused. Expired connections may be closed lazily before reuse. If it &lt;= 0, connections are not closed due to a connection's age.&#13;
  # The value is a duration string. A duration string is a possibly signed sequence of decimal numbers, each with optional fraction and a unit suffix, such as '300ms', '-1.5h' or '2h45m'. Valid time units are 'ns', 'us' (or 'µs'), 'ms', 's', 'm', 'h'.&#13;
  conn_max_lifetime: 5m&#13;
  # The maximum amount of time a connection may be idle. Expired connections may be closed lazily before reuse. If it &lt;= 0, connections are not closed due to a connection's idle time.&#13;
  # The value is a duration string. A duration string is a possibly signed sequence of decimal numbers, each with optional fraction and a unit suffix, such as '300ms', '-1.5h' or '2h45m'. Valid time units are 'ns', 'us' (or 'µs'), 'ms', 's', 'm', 'h'.&#13;
  conn_max_idle_time: 0&#13;
&#13;
# The default data volume&#13;
data_volume: /data&#13;
&#13;
# Harbor Storage settings by default is using /data dir on local filesystem&#13;
# Uncomment storage_service setting If you want to using external storage&#13;
# storage_service:&#13;
#   # ca_bundle is the path to the custom root ca certificate, which will be injected into the truststore&#13;
#   # of registry's containers.  This is usually needed when the user hosts a internal storage with self signed certificate.&#13;
#   ca_bundle:&#13;
&#13;
#   # storage backend, default is filesystem, options include filesystem, azure, gcs, s3, swift and oss&#13;
#   # for more info about this configuration please refer https://distribution.github.io/distribution/about/configuration/&#13;
#   # and https://distribution.github.io/distribution/storage-drivers/&#13;
#   filesystem:&#13;
#     maxthreads: 100&#13;
#   # set disable to true when you want to disable registry redirect&#13;
#   redirect:&#13;
#     disable: false&#13;
&#13;
# Trivy configuration&#13;
#&#13;
# Trivy DB contains vulnerability information from NVD, Red Hat, and many other upstream vulnerability databases.&#13;
# It is downloaded by Trivy from the GitHub release page https://github.com/aquasecurity/trivy-db/releases and cached&#13;
# in the local file system. In addition, the database contains the update timestamp so Trivy can detect whether it&#13;
# should download a newer version from the Internet or use the cached one. Currently, the database is updated every&#13;
# 12 hours and published as a new release to GitHub.&#13;
trivy:&#13;
  # ignoreUnfixed The flag to display only fixed vulnerabilities&#13;
  ignore_unfixed: false&#13;
  # skipUpdate The flag to enable or disable Trivy DB downloads from GitHub&#13;
  #&#13;
  # You might want to enable this flag in test or CI/CD environments to avoid GitHub rate limiting issues.&#13;
  # If the flag is enabled you have to download the `trivy-offline.tar.gz` archive manually, extract `trivy.db` and&#13;
  # `metadata.json` files and mount them in the `/home/scanner/.cache/trivy/db` path.&#13;
  skip_update: false&#13;
  #&#13;
  # skipJavaDBUpdate If the flag is enabled you have to manually download the `trivy-java.db` file and mount it in the&#13;
  # `/home/scanner/.cache/trivy/java-db/trivy-java.db` path&#13;
  skip_java_db_update: false&#13;
  #&#13;
  # The offline_scan option prevents Trivy from sending API requests to identify dependencies.&#13;
  # Scanning JAR files and pom.xml may require Internet access for better detection, but this option tries to avoid it.&#13;
  # For example, the offline mode will not try to resolve transitive dependencies in pom.xml when the dependency doesn't&#13;
  # exist in the local repositories. It means a number of detected vulnerabilities might be fewer in offline mode.&#13;
  # It would work if all the dependencies are in local.&#13;
  # This option doesn't affect DB download. You need to specify 'skip-update' as well as 'offline-scan' in an air-gapped environment.&#13;
  offline_scan: false&#13;
  #&#13;
  # Comma-separated list of what security issues to detect. Possible values are `vuln`, `config` and `secret`. Defaults to `vuln`.&#13;
  security_check: vuln&#13;
  #&#13;
  # insecure The flag to skip verifying registry certificate&#13;
  insecure: false&#13;
  #&#13;
  # timeout The duration to wait for scan completion.&#13;
  # There is upper bound of 30 minutes defined in scan job. So if this `timeout` is larger than 30m0s, it will also timeout at 30m0s.&#13;
  timeout: 5m0s&#13;
  #&#13;
  # github_token The GitHub access token to download Trivy DB&#13;
  #&#13;
  # Anonymous downloads from GitHub are subject to the limit of 60 requests per hour. Normally such rate limit is enough&#13;
  # for production operations. If, for any reason, it's not enough, you could increase the rate limit to 5000&#13;
  # requests per hour by specifying the GitHub access token. For more details on GitHub rate limiting please consult&#13;
  # https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting&#13;
  #&#13;
  # You can create a GitHub token by following the instructions in&#13;
  # https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line&#13;
  #&#13;
  # github_token: xxx&#13;
&#13;
jobservice:&#13;
  # Maximum number of job workers in job service&#13;
  max_job_workers: 10&#13;
  # The jobLoggers backend name, only support 'STD_OUTPUT', 'FILE' and/or 'DB'&#13;
  job_loggers:&#13;
    - STD_OUTPUT&#13;
    - FILE&#13;
    # - DB&#13;
  # The jobLogger sweeper duration (ignored if `jobLogger` is `stdout`)&#13;
  logger_sweeper_duration: 1 #days&#13;
&#13;
notification:&#13;
  # Maximum retry count for webhook job&#13;
  webhook_job_max_retry: 3&#13;
  # HTTP client timeout for webhook job&#13;
  webhook_job_http_client_timeout: 3 #seconds&#13;
&#13;
# Log configurations&#13;
log:&#13;
  # options are debug, info, warning, error, fatal&#13;
  level: info&#13;
  # configs for logs in local storage&#13;
  local:&#13;
    # Log files are rotated log_rotate_count times before being removed. If count is 0, old versions are removed rather than rotated.&#13;
    rotate_count: 50&#13;
    # Log files are rotated only if they grow bigger than log_rotate_size bytes. If size is followed by k, the size is assumed to be in kilobytes.&#13;
    # If the M is used, the size is in megabytes, and if G is used, the size is in gigabytes. So size 100, size 100k, size 100M and size 100G&#13;
    # are all valid.&#13;
    rotate_size: 200M&#13;
    # The directory on your host that store log&#13;
    location: /var/log/harbor&#13;
&#13;
  # Uncomment following lines to enable external syslog endpoint.&#13;
  # external_endpoint:&#13;
  #   # protocol used to transmit log to external endpoint, options is tcp or udp&#13;
  #   protocol: tcp&#13;
  #   # The host of external endpoint&#13;
  #   host: localhost&#13;
  #   # Port of external endpoint&#13;
  #   port: 5140&#13;
&#13;
#This attribute is for migrator to detect the version of the .cfg file, DO NOT MODIFY!&#13;
_version: 2.11.0&#13;
&#13;
# Uncomment external_database if using external database.&#13;
# external_database:&#13;
#   harbor:&#13;
#     host: harbor_db_host&#13;
#     port: harbor_db_port&#13;
#     db_name: harbor_db_name&#13;
#     username: harbor_db_username&#13;
#     password: harbor_db_password&#13;
#     ssl_mode: disable&#13;
#     max_idle_conns: 2&#13;
#     max_open_conns: 0&#13;
&#13;
# Uncomment redis if need to customize redis db&#13;
# redis:&#13;
#   # db_index 0 is for core, it's unchangeable&#13;
#   # registry_db_index: 1&#13;
#   # jobservice_db_index: 2&#13;
#   # trivy_db_index: 5&#13;
#   # it's optional, the db for harbor business misc, by default is 0, uncomment it if you want to change it.&#13;
#   # harbor_db_index: 6&#13;
#   # it's optional, the db for harbor cache layer, by default is 0, uncomment it if you want to change it.&#13;
#   # cache_layer_db_index: 7&#13;
&#13;
# Uncomment external_redis if using external Redis server&#13;
# external_redis:&#13;
#   # support redis, redis+sentinel&#13;
#   # host for redis: &lt;host_redis&gt;:&lt;port_redis&gt;&#13;
#   # host for redis+sentinel:&#13;
#   #  &lt;host_sentinel1&gt;:&lt;port_sentinel1&gt;,&lt;host_sentinel2&gt;:&lt;port_sentinel2&gt;,&lt;host_sentinel3&gt;:&lt;port_sentinel3&gt;&#13;
#   host: redis:6379&#13;
#   password: &#13;
#   # Redis AUTH command was extended in Redis 6, it is possible to use it in the two-arguments AUTH &lt;username&gt; &lt;password&gt; form.&#13;
#   # there's a known issue when using external redis username ref:https://github.com/goharbor/harbor/issues/18892&#13;
#   # if you care about the image pull/push performance, please refer to this https://github.com/goharbor/harbor/wiki/Harbor-FAQs#external-redis-username-password-usage&#13;
#   # username:&#13;
#   # sentinel_master_set must be set to support redis+sentinel&#13;
#   #sentinel_master_set:&#13;
#   # db_index 0 is for core, it's unchangeable&#13;
#   registry_db_index: 1&#13;
#   jobservice_db_index: 2&#13;
#   trivy_db_index: 5&#13;
#   idle_timeout_seconds: 30&#13;
#   # it's optional, the db for harbor business misc, by default is 0, uncomment it if you want to change it.&#13;
#   # harbor_db_index: 6&#13;
#   # it's optional, the db for harbor cache layer, by default is 0, uncomment it if you want to change it.&#13;
#   # cache_layer_db_index: 7&#13;
&#13;
# Uncomment uaa for trusting the certificate of uaa instance that is hosted via self-signed cert.&#13;
# uaa:&#13;
#   ca_file: /path/to/ca&#13;
&#13;
# Global proxy&#13;
# Config http proxy for components, e.g. http://my.proxy.com:3128&#13;
# Components doesn't need to connect to each others via http proxy.&#13;
# Remove component from `components` array if want disable proxy&#13;
# for it. If you want use proxy for replication, MUST enable proxy&#13;
# for core and jobservice, and set `http_proxy` and `https_proxy`.&#13;
# Add domain to the `no_proxy` field, when you want disable proxy&#13;
# for some special registry.&#13;
proxy:&#13;
  http_proxy:&#13;
  https_proxy:&#13;
  no_proxy:&#13;
  components:&#13;
    - core&#13;
    - jobservice&#13;
    - trivy&#13;
&#13;
# metric:&#13;
#   enabled: false&#13;
#   port: 9090&#13;
#   path: /metrics&#13;
&#13;
# Trace related config&#13;
# only can enable one trace provider(jaeger or otel) at the same time,&#13;
# and when using jaeger as provider, can only enable it with agent mode or collector mode.&#13;
# if using jaeger collector mode, uncomment endpoint and uncomment username, password if needed&#13;
# if using jaeger agetn mode uncomment agent_host and agent_port&#13;
# trace:&#13;
#   enabled: true&#13;
#   # set sample_rate to 1 if you wanna sampling 100% of trace data; set 0.5 if you wanna sampling 50% of trace data, and so forth&#13;
#   sample_rate: 1&#13;
#   # # namespace used to differentiate different harbor services&#13;
#   # namespace:&#13;
#   # # attributes is a key value dict contains user defined attributes used to initialize trace provider&#13;
#   # attributes:&#13;
#   #   application: harbor&#13;
#   # # jaeger should be 1.26 or newer.&#13;
#   # jaeger:&#13;
#   #   endpoint: http://hostname:14268/api/traces&#13;
#   #   username:&#13;
#   #   password:&#13;
#   #   agent_host: hostname&#13;
#   #   # export trace data by jaeger.thrift in compact mode&#13;
#   #   agent_port: 6831&#13;
#   # otel:&#13;
#   #   endpoint: hostname:4318&#13;
#   #   url_path: /v1/traces&#13;
#   #   compression: false&#13;
#   #   insecure: true&#13;
#   #   # timeout is in seconds&#13;
#   #   timeout: 10&#13;
&#13;
# Enable purge _upload directories&#13;
upload_purging:&#13;
  enabled: true&#13;
  # remove files in _upload directories which exist for a period of time, default is one week.&#13;
  age: 168h&#13;
  # the interval of the purge operations&#13;
  interval: 24h&#13;
  dryrun: false&#13;
&#13;
# Cache layer configurations&#13;
# If this feature enabled, harbor will cache the resource&#13;
# `project/project_metadata/repository/artifact/manifest` in the redis&#13;
# which can especially help to improve the performance of high concurrent&#13;
# manifest pulling.&#13;
# NOTICE&#13;
# If you are deploying Harbor in HA mode, make sure that all the harbor&#13;
# instances have the same behaviour, all with caching enabled or disabled,&#13;
# otherwise it can lead to potential data inconsistency.&#13;
cache:&#13;
  # not enabled by default&#13;
  enabled: false&#13;
  # keep cache for one day by default&#13;
  expire_hours: 24&#13;
&#13;
# Harbor core configurations&#13;
# Uncomment to enable the following harbor core related configuration items.&#13;
# core:&#13;
#   # The provider for updating project quota(usage), there are 2 options, redis or db,&#13;
#   # by default is implemented by db but you can switch the updation via redis which&#13;
#   # can improve the performance of high concurrent pushing to the same project,&#13;
#   # and reduce the database connections spike and occupies.&#13;
#   # By redis will bring up some delay for quota usage updation for display, so only&#13;
#   # suggest switch provider to redis if you were ran into the db connections spike around&#13;
#   # the scenario of high concurrent pushing to same project, no improvement for other scenes.&#13;
#   quota_update_provider: redis # Or db&#13;
。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/harbor.yaml.html</guid><pubDate>Wed, 12 Jun 2024 02:44:52 +0000</pubDate></item><item><title>gitlab.yaml</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/gitlab.yaml.html</link><description>```yaml&#13;
version: '3.6'&#13;
services:&#13;
  gitlab:&#13;
    image: gitlab/gitlab-ce:latest&#13;
    container_name: gitlab&#13;
    restart: always&#13;
    hostname: '172.16.8.3'&#13;
    environment:&#13;
      GITLAB_OMNIBUS_CONFIG: |&#13;
        external_url 'http://172.16.8.3:8929'&#13;
        gitlab_rails['gitlab_shell_ssh_port'] = 2424&#13;
    ports:&#13;
      - '8929:8929'&#13;
      - '4443:443'&#13;
      - '2424:22'&#13;
    volumes:&#13;
      - '/srv/config:/etc/gitlab'&#13;
      - '/srv/logs:/var/log/gitlab'&#13;
      - '/srv/data:/var/opt/gitlab'&#13;
    shm_size: '256m'。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/gitlab.yaml.html</guid><pubDate>Wed, 12 Jun 2024 02:40:16 +0000</pubDate></item><item><title>K8S灾难恢复</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/K8S-zai-nan-hui-fu.html</link><description>![image](https://github.com/donkeytt11111/jiaxin.github.io/assets/167744103/4817925f-e8c4-4e62-a983-b1439f36ac84)&#13;
。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/K8S-zai-nan-hui-fu.html</guid><pubDate>Wed, 12 Jun 2024 00:39:01 +0000</pubDate></item><item><title>talos</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/talos.html</link><description>![image](https://github.com/donkeytt11111/jiaxin.github.io/assets/167744103/86f3f38b-b49e-4fa7-b7b6-47d3507d76a1)&#13;
&#13;
&#13;
。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/talos.html</guid><pubDate>Tue, 11 Jun 2024 09:30:55 +0000</pubDate></item><item><title>test_auto</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/test_auto.html</link><description>[case_test.zip](https://github.com/user-attachments/files/15785392/case_test.zip)&#13;
&#13;
&#13;
。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/test_auto.html</guid><pubDate>Tue, 11 Jun 2024 09:17:52 +0000</pubDate></item><item><title>k8s_status</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/k8s_status.html</link><description>echo '开始检查k8s集群状态'&#13;
while true; do&#13;
  # 尝试获取所有Pod的状态信息，直到成功&#13;
  while true; do&#13;
    pod_statuses=$(kubectl get pods -A --output=json 2&gt;&amp;1)&#13;
    if [[ $(echo '$pod_statuses' | jq -r '.items[] | select(.metadata.namespace == 'kube-system')') ]]; then  # 检查kube-system是否存在&#13;
      echo '成功连接到Kubernetes集群'&#13;
      break&#13;
    fi&#13;
    echo '无法获取kube-system命名空间的Pod信息。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/k8s_status.html</guid><pubDate>Tue, 11 Jun 2024 09:13:44 +0000</pubDate></item><item><title>project_ddi</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/project_ddi.html</link><description>```shell&#13;
#!/bin/bash&#13;
#集团文件夹下方执行&#13;
#执行之前确定/path/to/dhcpdb_create.pgsql有没有这个文件&#13;
&#13;
&#13;
&#13;
source_config_path='/root/.kube/config'&#13;
helm_path='cncp-helm'&#13;
services_path='cncp-helm/cncp-basic-services/values.yaml'&#13;
core_path='cncp-helm/cncp-core-components/values.yaml'&#13;
one_path=$1&#13;
tow_path=$2&#13;
ipv4_path='172.16.102.240-172.16.102.244'&#13;
ipv6_path='2408:8631:c02:ffa2::240-2408:8631:c02:ffa2::244'&#13;
dns_path=$3&#13;
dhcp_path=$4&#13;
ddi_file_path='cncp-helm/ddi-components/values.yaml'&#13;
ddi_dns_path=$5&#13;
ddi_dhcp_path=$6&#13;
sql_path=$7&#13;
&#13;
&#13;
# bak&#13;
#backup_suffix='_$(date +%Y%m%d%H%M%S).bak'&#13;
#cp '$services_path' '${services_path}${backup_suffix}'&#13;
#cp '$core_path' '${core_path}${backup_suffix}'&#13;
&#13;
#echo '服务路径（$services_path）和核心路径（$core_path）的备份已完成。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/project_ddi.html</guid><pubDate>Tue, 11 Jun 2024 09:12:58 +0000</pubDate></item><item><title>talos_master</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/talos_master.html</link><description>```shell&#13;
#!/bin/bash&#13;
# 参数检查&#13;
talosctl_version='talosctl version'&#13;
talosctl_service='talosctl service'&#13;
command_jiqun='talosctl kubeconfig'&#13;
kubectl_version='kubectl get pods -A'&#13;
#生成配置文件&#13;
command_token='talosctl  gen  config  mingyang https://172.16.102.102:6443  --config-patch-control-plane @patch.yaml --config-patch-worker @patch-worker.yaml'&#13;
all_file_name=*&#13;
patch_name=patch*&#13;
k8s_path=/home/k8s&#13;
failpath=/opt&#13;
jituan_path=$1&#13;
talos_path=$2&#13;
cncp_path=$3&#13;
ipv46_patch=$4&#13;
linshi_ip=$5&#13;
talos_cfg=$6&#13;
del_jt=${failpath}/${jituan_path}&#13;
ctrl_file=${failpath}/${jituan_path}/${talos_path}/controlplane.yaml&#13;
taloscfg_file=${failpath}/${jituan_path}/${talos_path}/talosconfig&#13;
talos_file_path=${failpath}/${jituan_path}/${talos_path}&#13;
&#13;
&#13;
# 检查参数个数是否满足要求&#13;
if [[ $# -lt 6 ]]; then&#13;
    echo '使用错误！使用方法 sh danji.sh 集团名 talos cncp-helm 要修改的IP地址!主机位! 临时IP地址绑定的地址!主机位! talosconfig中的IP地址!主机位!'&#13;
    exit 1&#13;
fi&#13;
&#13;
# 逐个检查参数是否合法（以检查非空且非仅空格字符为例）&#13;
for ((i=1; i&lt;=6; i++)); do&#13;
    param='${!i}'&#13;
    if [[ -z '$param' || '$param' =~ ^\s+$ ]]; then&#13;
        echo '使用错误！使用方法 sh danji.sh 集团名 talos cncp-helm 要修改的IP地址!主机位! 临时IP地址绑定的地址!主机位! talosconfig中的IP地址!主机位!'&#13;
        exit 1&#13;
    fi&#13;
done&#13;
&#13;
# 所有参数检查通过，记录日志并继续执行&#13;
&#13;
kubecfg_path='/root/.kube/config'&#13;
if rm '$kubecfg_path'; then&#13;
  echo '文件 '$kubecfg_path' 已成功删除。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/talos_master.html</guid><pubDate>Tue, 11 Jun 2024 09:11:48 +0000</pubDate></item><item><title>k8s_delete.sh</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/k8s_delete.sh.html</link><description>```shell&#13;
#!/bin/bash&#13;
function delete_pods_by_status {&#13;
    local namespace='$1'&#13;
    local status='$2'&#13;
    kubectl -n '$namespace' get pods | grep '$status' | awk '{print $1}' | xargs kubectl -n '$namespace' delete pods&#13;
}&#13;
&#13;
#ERROR&#13;
delete_pods_by_status 'default' 'Error'&#13;
delete_pods_by_status 'cncp-system' 'Error'&#13;
delete_pods_by_status 'metallb-system' 'Error'&#13;
delete_pods_by_status 'kubernetes-dashboard' 'Error'&#13;
delete_pods_by_status 'openebs' 'Error'&#13;
delete_pods_by_status 'kube-system' 'Error'&#13;
&#13;
#completed&#13;
delete_pods_by_status 'default' 'Completed'&#13;
delete_pods_by_status 'cncp-system' 'Completed'&#13;
delete_pods_by_status 'metallb-system' 'Completed'&#13;
delete_pods_by_status 'kubernetes-dashboard' 'Completed'&#13;
delete_pods_by_status 'openebs' 'Completed'&#13;
delete_pods_by_status 'kube-system' 'Completed'。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/k8s_delete.sh.html</guid><pubDate>Fri, 07 Jun 2024 09:07:47 +0000</pubDate></item><item><title>harbor部署</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/harbor-bu-shu.html</link><description>wget https://github.com/goharbor/harbor/releases/download/v2.11.0/harbor-offline-installer-v2.11.0.tgz&#13;
解压压缩包&#13;
复制compose文件&#13;
![image](https://github.com/donkeytt11111/jiaxin.github.io/assets/167744103/fcc2629c-8bd9-4889-97b3-c4c5cf1e88a0)&#13;
#修改配置文件中的端口和hostname&#13;
vim harbor.yml&#13;
👍 &#13;
# 生成私钥&#13;
openssl genrsa -out 172.16.8.3.key 2048&#13;
# 生成CSR（证书签署请求）&#13;
openssl req -new -key 172.16.8.3.key -out 172.16.8.3.csr&#13;
# 用私钥生成自签名证书&#13;
openssl x509 -req -days 365 -in 172.16.8.3.csr -signkey 172.16.8.3.key -out 172.16.8.3.crt&#13;
&#13;
💯 #新版修复&#13;
openssl x509 -req -days 365 -in 172.16.8.3.csr -CA 172.16.8.3.crt -CAkey 172.16.8.3.key -set_serial 01 -out 172.16.8.3.crt -extfile &lt;(echo -e 'subjectAltName = IP:172.16.8.3')&#13;
👍 &#13;
#修改配置文件&#13;
https:&#13;
  enabled: true&#13;
  port: 443&#13;
  certificate: /home/test/harbor/harbor/172.16.8.3.crt&#13;
  private_key: /home/test/harbor/harbor/172.16.8.3.key&#13;
👍 &#13;
#执行脚本&#13;
./prepre&#13;
👍 &#13;
#执行安装脚本&#13;
install&#13;
#配置登录模块&#13;
sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'&#13;
&gt; {&#13;
&gt; 'insecure-registries':['172.16.8.3']&#13;
&gt; }&#13;
&gt; EOF&#13;
。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/harbor-bu-shu.html</guid><pubDate>Fri, 07 Jun 2024 07:24:26 +0000</pubDate></item><item><title>禅道部署</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/shan-dao-bu-shu.html</link><description>docker pull hub.zentao.net/app/zentao:18.5 &#13;
&#13;
&#13;
&#13;
docker run \&#13;
--name zentao \&#13;
-p 80:8888 \&#13;
--network=tt \&#13;
-v /data/zentao:/home/ljx/data \&#13;
-e MYSQL_INTERNAL=true \&#13;
hub.zentao.net/app/zentao:18.5&#13;
&#13;
&#13;
&#13;
docker run -d -v /home/data:/data -p 8888:80 -e MYSQL_INTERNAL=true hub.zentao.net/app/zentao:18.5&#13;
&#13;
http://120.46.211.167:8888/&#13;
。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/shan-dao-bu-shu.html</guid><pubDate>Thu, 06 Jun 2024 02:40:39 +0000</pubDate></item><item><title>helm转yaml方法</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/helm-zhuan-yaml-fang-fa.html</link><description>#1.首先需要一个http服务器，通过docker或者在centos上直接yum install 部署都可以&#13;
docker run -d -p 8081:80 -v /var/www:/usr/local/apache2/htdocs httpd&#13;
这个docker命令会创建并运行一个httpd容器,参数说明如下:&#13;
&#13;
-d: 后台运行容器&#13;
-p 8081:80: 映射容器内80端口到宿主机8081端口&#13;
-v /var/www:/usr/local/apache2/htdocs: 把宿主机/var/www目录挂载到容器的/usr/local/apache2/htdocs,作为网页文档根目录&#13;
httpd: 使用httpd镜像启动容器&#13;
这样就在宿主机8081端口启动了一个httpd服务器,网页文档来自宿主机的/var/www目录。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/helm-zhuan-yaml-fang-fa.html</guid><pubDate>Thu, 06 Jun 2024 02:36:16 +0000</pubDate></item><item><title>集群快照备份</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/ji-qun-kuai-zhao-bei-fen.html</link><description>snap install yq&#13;
&#13;
#创建etcd节点数据库备份&#13;
talosctl -n 172.16.8.70 etcd snapshot db.snapshot&#13;
&#13;
#若etcd状态异常则通过目录挂载方式备份快照&#13;
talosctl -n 172.16.8.70 cp /var/lib/etcd/member/snap/db .&#13;
&#13;
#备份yaml文件&#13;
talosctl -n 172.16.8.70 get mc v1alpha1 -o yaml | yq eval '.spec' - &gt; machine_config.yaml&#13;
&#13;
确保没有具有机器类型的控制平面节点init：&#13;
&#13;
talosctl -n 172.16.8.70,172.16.8.71,172.16.8.72 get machinetype&#13;
NODE         NAMESPACE   TYPE          ID             VERSION   TYPE&#13;
172.20.0.2   config      MachineType   machine-type   2         controlplane&#13;
172.20.0.4   config      MachineType   machine-type   2         controlplane&#13;
172.20.0.3   config      MachineType   machine-type   2         controlplane&#13;
&#13;
#重置并重启&#13;
talosctl -n 172.16.8.70 reset --graceful=false --reboot --system-labels-to-wipe=EPHEMERAL&#13;
&#13;
#恢复备份&#13;
talosctl -n 172.16.8.70 bootstrap --recover-from=./db.snapshot&#13;
&#13;
![image](https://github.com/donkeytt11111/jiaxin.github.io/assets/167744103/f5dfde30-bce8-4ff7-900b-f5d99af109ac)。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/ji-qun-kuai-zhao-bei-fen.html</guid><pubDate>Thu, 06 Jun 2024 02:30:37 +0000</pubDate></item><item><title>集群证书替换方案</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/ji-qun-zheng-shu-ti-huan-fang-an.html</link><description>先看是几个节点的集群，需要在每个节点执行以下操作。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/ji-qun-zheng-shu-ti-huan-fang-an.html</guid><pubDate>Thu, 06 Jun 2024 02:00:28 +0000</pubDate></item><item><title>hb_docker.sh</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/hb_docker.sh.html</link><description>```shell&#13;
#!/bin/bash&#13;
Harbor_Address=172.16.1.200       #Harbor主机地址&#13;
Harbor_User=admin                      #登录Harbor的用户&#13;
Harbor_Passwd=Harbor12345              #登录Harbor的用户密码&#13;
Images_File=./images.list      # 镜像清单文件&#13;
Tar_File=/backup/Harbor-backup/                 #镜像tar包存放路径&#13;
set -x&#13;
&#13;
# 获取Harbor中所有的项目（Projects）&#13;
Project_List=$(curl -u admin:Harbor12345  -H 'Content-Type: application/json' -X GET  https://$Harbor_Address/api/v2.0/projects  -k  | python3 -m json.tool | grep name | awk '/'name': /' | awk -F ''' '{print $4}')&#13;
&#13;
for Project in $Project_List;do&#13;
   # 循环获取项目下所有的镜像&#13;
    Image_Names=$(curl -u admin:Harbor12345 -H 'Content-Type: application/json' -X GET https://$Harbor_Address/api/v2.0/projects/$Project/repositories -k | python3 -m json.tool | grep name | awk '/'name': /' | awk -F ''' '{print $4}')&#13;
    for Image in $Image_Names;do&#13;
        # 循环获取镜像的版本（tag)&#13;
        Image_Tags=$(curl -u admin:Harbor12345  -H 'Content-Type: application/json'   -X GET  https://$Harbor_Address/v2/$Image/tags/list  -k |  awk -F '''  '{print $8,$10,$12}')&#13;
       for Tag in $Image_Tags;do&#13;
            # 格式化输出镜像信息&#13;
            echo '$Harbor_Address/$Image:$Tag'   &gt;&gt; harbor-images-`date '+%Y-%m-%d'`.txt&#13;
        done&#13;
    done&#13;
done&#13;
&#13;
# 读取Images_File文件中的镜像名称&#13;
while read -r image_tag; do&#13;
    # 使用awk提取镜像名称和标签，同时处理特殊字符&#13;
    image_Name=$(echo $image_tag | awk -F/ '{print $3}' |  awk -F: '{print $1}' | sed 's/\//-/g')&#13;
    image_Lable=$(echo $image_tag | awk -F/ '{print $3}' |  awk -F: '{print $2}' | sed 's/:/_/g')&#13;
&#13;
    # 检查image_Name和image_Lable是否为空&#13;
    if [ -z '$image_Name' ]; then&#13;
        echo 'Error: Empty image_Name for $image_tag' &gt;&gt; error_images.txt&#13;
        continue&#13;
    fi&#13;
    if [ -z '$image_Lable' ]; then&#13;
        echo 'Error: Empty image_Lable for $image_tag' &gt;&gt; error_images.txt&#13;
        continue&#13;
    fi&#13;
&#13;
    # 创建安全的文件名&#13;
    image_save='$image_Name-$image_Lable'&#13;
&#13;
    docker pull $Harbor_Address/$image_tag&#13;
    docker tag $Harbor_Address/$image_tag $image_tag&#13;
    docker save $image_tag -o '$Tar_File/$image_save.tar'&#13;
    docker rmi $Harbor_Address/$image_tag&#13;
    docker rmi $image_tag&#13;
done &lt; '$Images_File'&#13;
。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/hb_docker.sh.html</guid><pubDate>Wed, 05 Jun 2024 07:16:57 +0000</pubDate></item><item><title>email</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/email.html</link><description>```shell&#13;
#!/bin/bash&#13;
&#13;
&#13;
&#13;
# 发送邮件方法&#13;
function send_config_files_by_email() {&#13;
    project_name=$1&#13;
&#13;
    echo '请输入你部署的项目的名字，英文，若输入错误 请用ctrl+w撤回后重新输入'&#13;
    read project_name&#13;
&#13;
    # 定义接收者列表&#13;
    recipients=('1553232697@qq.com' '18640549232@163.com' '442283241@qq.com' '2505584859@qq.com' '1223645860@qq.com')&#13;
&#13;
    # 定义要发送的配置文件列表&#13;
    config_files=('/root/.kube/config' '/root/.talos/config')&#13;
&#13;
    # 安装msmtp和mailx&#13;
    install_deps() {&#13;
        if command -v yum &amp;&gt; /dev/null; then&#13;
            echo '正在为CentOS/RHEL系统安装必要软件...'&#13;
            sudo yum install -y msmtp ca-certificates mailx&#13;
        else&#13;
            echo '无法识别的包管理器，请手动安装msmtp和mailx。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/email.html</guid><pubDate>Wed, 05 Jun 2024 07:11:06 +0000</pubDate></item><item><title>K8S集群IP迁移方案</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/K8S-ji-qun-IP-qian-yi-fang-an.html</link><description>![image](https://github.com/donkeytt11111/jiaxin.github.io/assets/167744103/df4eac8d-85f4-4e83-bc69-c4b2f34ef6e0)&#13;
👍 先修改master3&#13;
👍 :%s/172.16.8.70/172.16.102.70/g&#13;
![image](https://github.com/donkeytt11111/jiaxin.github.io/assets/167744103/44e9920b-3a94-45bf-bc96-d3d7ccc9ff9f)&#13;
👍 新增&#13;
master2 master1 同理&#13;
👍 master1注意network下面的IP要改回之前的参照下图(因为全局替换了)&#13;
![image](https://github.com/donkeytt11111/jiaxin.github.io/assets/167744103/ca265ed9-9a8b-498d-9066-ae19f96467de)&#13;
👍 将 /root/.tallos 和kube 改为新节点master1的IP&#13;
👍 kubectl edit configmap  cluster-config -n kube-system 将IP改为新地址IP&#13;
👍 talosctl reboot -n ms1,ms2,ms3(IP)&#13;
👍 重启完成后，将网关修改新的网关，旧IP删除&#13;
![image](https://github.com/donkeytt11111/jiaxin.github.io/assets/167744103/814dcc35-22fd-429f-bd60-ac0b7417fe18)&#13;
![image](https://github.com/donkeytt11111/jiaxin.github.io/assets/167744103/817a5bf1-9c84-434c-8d4e-caa9e35205ce)。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/K8S-ji-qun-IP-qian-yi-fang-an.html</guid><pubDate>Wed, 05 Jun 2024 05:26:57 +0000</pubDate></item><item><title>jenkins部署</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/jenkins-bu-shu.html</link><description>docker pull jenkins/jenkins&#13;
&#13;
docker run \&#13;
  -u root \&#13;
  --rm \&#13;
  -d \&#13;
  -p 8080:8080 \&#13;
  -p 50000:50000 \&#13;
  -v jenkins-data:/var/jenkins_home \&#13;
  -v /var/run/docker.sock:/var/run/docker.sock \&#13;
  --name jenkins \&#13;
  jenkins/jenkins:latest。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/jenkins-bu-shu.html</guid><pubDate>Wed, 05 Jun 2024 00:41:44 +0000</pubDate></item><item><title>Gitlab部署</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/Gitlab-bu-shu.html</link><description>vim /etc/ssh/sshd_config&#13;
Port = 2424&#13;
&#13;
systemctl restart sshd&#13;
&#13;
mkdir -p /srv/gitlab&#13;
&#13;
export GITLAB_HOME=/srv/gitlab&#13;
&#13;
```golang&#13;
&#13;
version: '3.6'&#13;
services:&#13;
  gitlab:&#13;
    image: gitlab/gitlab-ce:latest&#13;
    container_name: gitlab&#13;
    restart: always&#13;
    hostname: '172.16.8.3'&#13;
    environment:&#13;
      GITLAB_OMNIBUS_CONFIG: |&#13;
        external_url 'http://172.16.8.3:8929'&#13;
        gitlab_rails['gitlab_shell_ssh_port'] = 2424&#13;
    ports:&#13;
      - '8929:8929'&#13;
      - '4443:443'&#13;
      - '2424:22'&#13;
    volumes:&#13;
      - '/srv/config:/etc/gitlab'&#13;
      - '/srv/logs:/var/log/gitlab'&#13;
      - '/srv/data:/var/opt/gitlab'&#13;
    shm_size: '256m'&#13;
。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/Gitlab-bu-shu.html</guid><pubDate>Wed, 05 Jun 2024 00:39:51 +0000</pubDate></item><item><title>PXE系统部署</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/PXE-xi-tong-bu-shu.html</link><description>✧ 使用http用来发布linux系统的安装树（也可以使用NFS、FTP server或HTTPS）&#13;
✧ DHCP server为客户端分配ip并提供TFTP服务器地址及PXE启动文件位置&#13;
✧ TFTP server为客户端提供引导文件。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/PXE-xi-tong-bu-shu.html</guid><pubDate>Tue, 04 Jun 2024 09:07:13 +0000</pubDate></item><item><title>harbor自动化拉取镜像方案</title><link>https://donkeytt11111.github.io/jiaxin.github.io/post/harbor-zi-dong-hua-la-qu-jing-xiang-fang-an.html</link><description>grep data_volume  /app/harbor/harbor.yml    #根据配置文件查找数据存储目录&#13;
data_volume: /data&#13;
&#13;
cd /data/registry     #进入到Harbor的数据目录下&#13;
&#13;
find  docker/   -type  d  -name 'current'  | sed  's|docker/registry/v2/repositories/||g;s|/_manifests/tags/|:|g;s|/current||g'  &gt;  images.list&#13;
&#13;
cat images.list&#13;
 &#13;
curl https://192.168.2.250:443/api/version  -k&#13;
{'version':'v2.0'}&#13;
![image](https://github.com/donkeytt11111/jiaxin.github.io/assets/167744103/2390402e-6803-45a1-bf0d-e99f0347395d)&#13;
&#13;
&#13;
&#13;
```shell&#13;
#!/bin/bash&#13;
Harbor_Address=172.16.1.200       #Harbor主机地址&#13;
Harbor_User=admin                      #登录Harbor的用户&#13;
Harbor_Passwd=Harbor12345              #登录Harbor的用户密码&#13;
Images_File=./images.list   # 镜像清单文件&#13;
Tar_File=/backup/Harbor-backup/                 #镜像tar包存放路径&#13;
set -x&#13;
# 获取Harbor中所有的项目（Projects）&#13;
Project_List=$(curl -u admin:Harbor12345  -H 'Content-Type: application/json' -X GET  https://172.16.1.200/api/v2.0/projects  -k  | python3 -m json.tool | grep name | awk '/'name': /' | awk -F ''' '{print $4}')&#13;
&#13;
for Project in $Project_List;do&#13;
   # 循环获取项目下所有的镜像&#13;
    Image_Names=$(curl -u admin:Harbor12345 -H 'Content-Type: application/json' -X GET https://172.16.1.200/api/v2.0/projects/$Project/repositories -k | python3 -m json.tool | grep name | awk '/'name': /' | awk -F ''' '{print $4}')&#13;
    for Image in $Image_Names;do&#13;
        # 循环获取镜像的版本（tag)&#13;
        Image_Tags=$(curl -u admin:Harbor12345  -H 'Content-Type: application/json'   -X GET  https://172.16.1.200/v2/$Image/tags/list  -k |  awk -F '''  '{print $8,$10,$12}')&#13;
       for Tag in $Image_Tags;do&#13;
            # 格式化输出镜像信息&#13;
            echo '$Harbor_Address/$Image:$Tag'   &gt;&gt; harbor-images-`date '+%Y-%m-%d'`.txt&#13;
        done&#13;
    done&#13;
done&#13;
Image_tags=$(uniq $Images_File)&#13;
for image_tag in $Image_tags;do&#13;
    image_Name=$(echo $image_tag | awk -F/ '{print $3}' |  awk -F: '{print $1}')&#13;
    image_Lable=$(echo $image_tag | awk -F/ '{print $3}' |  awk -F: '{print $2}')&#13;
    #image_Name=$(echo $image_tag | awk -F ' +' '{print $1}')&#13;
    #image_Lable=$(echo $image_tag | awk -F ' +' '{print $2}')&#13;
    docker pull 172.16.1.200/$image_tag&#13;
    docker tag  172.16.1.200/$image_tag $image_tag&#13;
    docker save $image_tag  -o $image_Name.tar&#13;
    docker rmi  172.16.1.200/$image_tag&#13;
    docker rmi  $image_tag&#13;
    mv $image_Name.tar  $Tar_File&#13;
done&#13;
```&#13;
![image](https://github.com/donkeytt11111/jiaxin.github.io/assets/167744103/cdad1ceb-eb50-42ab-b84e-7e6fe15f9cb1)。</description><guid isPermaLink="true">https://donkeytt11111.github.io/jiaxin.github.io/post/harbor-zi-dong-hua-la-qu-jing-xiang-fang-an.html</guid><pubDate>Tue, 04 Jun 2024 06:37:38 +0000</pubDate></item></channel></rss>